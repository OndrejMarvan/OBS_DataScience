








# print(1_000_000 == 1000000)

import time
start = time.time()  # Start timing
# print(start )
# Code to be measured

total = 0
for i in range(1_000_000):
    total += i # total = total + i

print(total)
end = time.time()  # End timing
print(f"Execution time: {end - start:.6f} seconds")  # f"" allows inserting variables and expressions inside {}.

print(f"Execution time: {end - start:.3f} seconds") 

# print(f"Execution time: {4.155:.2f} seconds") 


total_1 = sum(range(1_000_000))

total = 0
for i in range(1_000_000):
    total += i # total = total + i,

total_1 == total   


import timeit

# Measure loop performance
time_taken = timeit.timeit("sum(range(1_000_000))", number=10)

print(f"Average execution time: {time_taken / 10:.6f} seconds")  # f"" allows inserting variables and expressions inside {}.

time_taken_1 = timeit.timeit('''
total = 0
for i in range(1_000_000):
    total += i # total = total + i ''',
      number=10)

print(f"Average execution time loop: {time_taken_1 / 10:.6f} seconds")  # f"" allows inserting variables and expressions inside {}.

time_taken_1/time_taken











# !pip install tqdm
from tqdm import tqdm
import time

for i in tqdm(range(10)):
    time.sleep(i)  # Simulates a long-running operation

# tqdm(range(10)) creates a progress bar for the for loop
# time.sleep(0.5) simulates code execution (e.g., data loading)






squares_1= [i**2 for i in tqdm(range(10))]

squares = []
for i in tqdm(range(10)):
    squares.append(i**2)
          
print(squares)            
print(squares_1)

time_taken_1 = timeit.timeit('''
from tqdm import tqdm
import time
squares_1= [i**2 for i in tqdm(range(10))]''',
      number=10)

time_taken_2 = timeit.timeit('''
from tqdm import tqdm
import time
squares = []
for i in tqdm(range(10)):
    squares.append(i**2)''',
      number=10)

print(time_taken_1/time_taken_2)
# print(time_taken_2)





def slow_function(x):
    time.sleep(0.1)
    return x**2

results = tqdm(map(slow_function, range(50)), total=5)

# map() executes slow_function(x)
# tqdm() tracks the progress of the operation (total=50 is needed because map() has no built-in counter)






import pandas as pd
tqdm.pandas()  # Enables tqdm support for pandas

# Define a function instead of using lambda
def square(x):
    return x ** 2

# Create a DataFrame
df = pd.DataFrame({"A": range(10_000_000)})
print(df)
# Apply the function using progress_apply()
df["B"] = df["A"].progress_apply(square)

df.head()
# progress_apply() adds a progress bar to operations on DataFrame columns.






import threading

def task():
    time.sleep(0.2)

threads = []
for _ in tqdm(range(10), desc="Starting threads"):
    t = threading.Thread(target=task)
    t.start()
    threads.append(t)

for t in threads:
    t.join()

t





import timeit

def tanuj(n=1000):
    return n * (n + 1) / 2

# Method 1: Using a loop
def sum_using_loop():
    total = 0
    for i in range(1000):
        total += i  # same as: total = total + i
    return total

# Method 2: Using the built-in sum() function
def sum_using_builtin():
    return sum(range(1000))

# Compare the execution time of both methods using timeit
loop_time = timeit.timeit(sum_using_loop, number=10000)
loop_tanuj = timeit.timeit(tanuj, number=10000)
builtin_time = timeit.timeit(sum_using_builtin, number=10000)

print(f"Loop time: {round(loop_time, 1)}")
print(f"loop_tanuj: {round(loop_tanuj, 1)}")
print(f"Built-in sum() time: {round(builtin_time, 1)}")

loop_time/builtin_time





import seaborn as sns
data = sns.load_dataset("iris")
# print(data.head())
# print(data.species.unique())
group_var = "species"
numeric_var = "petal_length"


results = {}
unique_groups = data[group_var].dropna().unique()

print(data[group_var].dropna().unique())

for group in unique_groups:
    # print(group)
    subset = data[data[group_var] == group][numeric_var]
    # print(subset)
    results[group] = subset.mean()

print(results)    

results_1 = data.groupby(group_var)[numeric_var].mean().to_dict()

print(results_1)

# # [numeric_var].mean().to_dict()


import timeit
import seaborn as sns

# Load the Iris dataset
data = sns.load_dataset("iris")

group_var = "species"
numeric_var = "petal_length"

# Measure execution time of the first solution (without groupby, using a for loop)
time_first_solution = timeit.timeit(
    stmt='''
results = {}
unique_groups = data[group_var].dropna().unique()
for group in unique_groups:
    subset = data[data[group_var] == group][numeric_var]
    results[group] = subset.mean()
    ''',
    setup='''
import seaborn as sns
data = sns.load_dataset("iris")
group_var = "species"
numeric_var = "petal_length"
    ''',
    number=100  # how many times to execute the code
)

# Measure execution time of the second solution (using groupby)
time_second_solution = timeit.timeit(
    stmt='''
results = data.groupby(group_var)[numeric_var].mean().to_dict()
    ''',
    setup='''
import seaborn as sns
data = sns.load_dataset("iris")
group_var = "species"
numeric_var = "petal_length"
    ''',
    number=100  # how many times to execute the code
)

# Print the results
print(f"Execution time for the for-loop: {round(time_first_solution, 3)} seconds")
print(f"Execution time for groupby: {round(time_second_solution, 3)} seconds")

print(f"The groupby method is faster than the iterative for-loop approach by: {round(time_second_solution - time_first_solution, 3)} seconds")

print(f"How much faster: {round(time_first_solution/time_second_solution, 3)} seconds")






import timeit
import pandas as pd

# List to store results
results_list = []

# Run the benchmark for 1000 iterations
for i in range(1000):
    # Measure execution time of the first solution (iteration through unique groups)
    time_first_solution = timeit.timeit(
        stmt='''
results = {}
unique_groups = data[group_var].dropna().unique()
for group in unique_groups:
    subset = data[data[group_var] == group][numeric_var]
    results[group] = subset.mean()
        ''',
        setup='''
import seaborn as sns
data = sns.load_dataset("iris")
group_var = "species"
numeric_var = "petal_length"
        ''',
        number=1  # how many times each repetition is executed
    )

    # Measure execution time of the second solution (using groupby)
    time_second_solution = timeit.timeit(
        stmt='''
results = data.groupby(group_var)[numeric_var].mean().to_dict()
        ''',
        setup='''
import seaborn as sns
data = sns.load_dataset("iris")
group_var = "species"
numeric_var = "petal_length"
        ''',
        number=1
    )

    # Add results as dictionaries
    results_list.append({
        'method': 'loop',
        'iteration': i,  # store exact execution time for each of the 1000 iterations
        'time': time_first_solution
    })
    results_list.append({
        'method': 'groupby',
        'iteration': i,  # store exact execution time for each of the 1000 iterations
        'time': time_second_solution
    })

# Convert the results list into a DataFrame
frame = pd.DataFrame(results_list)

# Display the results
frame






# 1. groupby("method") – groups the data in 'frame' by the values in the "method" column,
#    i.e., it analyzes the execution times separately for the 'loop' and 'groupby' methods.
# 2. ["time"] – selects the "time" column, which contains the measured execution times.
# 3. describe() – calculates basic descriptive statistics for each group.

# count – number of measurements (should be 1000, since we tested 1000 iterations)
# mean – average execution time
# std – standard deviation (the smaller it is, the more stable the result)
# min – shortest execution time
# 25%, 50% (median), 75% – quartiles (show the distribution of results)
# max – longest execution time

frame.groupby("method")["time"].describe()






import matplotlib.pyplot as plt
import seaborn as sns

# Create a figure with 1 row and 2 columns
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Create the first plot (boxplot)
sns.boxplot(x="method", y="time", data=frame, ax=axes[0])
axes[0].set_title('Boxplot of Execution Time for Both Methods')

# Create the second plot (violin plot)
sns.violinplot(x="method", y="time", data=frame, ax=axes[1])
axes[1].set_title('Violin Plot of Execution Time for Both Methods')

# Adjust layout to prevent overlap
plt.tight_layout()

# Show the plot
plt.show()






# Initialize empty lists representing matrices
matrix = list()
matrix2 = list()
result = list()

# Define the dimension of the square matrix
dimension = 100

# Create matrices with initial values
for rowI in range(0, dimension):
    row = list()   # Row for the first matrix
    row2 = list()  # Row for the second matrix
    row3 = list()  # Row for the result matrix (initialized with zeros)
    for columnI in range(0, dimension):
        row.append(rowI * dimension + columnI)   # Assign sequential values to the first matrix
        row2.append(rowI * dimension + columnI)  # Assign sequential values to the second matrix
        row3.append(0)                           # Initialize the result matrix with zeros
    # Add generated rows to the matrices
    matrix.append(row)
    matrix2.append(row2)
    result.append(row3)

print(matrix )
print(matrix2)
print(result)    

# Perform matrix multiplication
for resultRowI in range(0, dimension):          # Iterate through result matrix rows
    for resultColumnI in range(0, dimension):   # Iterate through result matrix columns
        result[resultRowI][resultColumnI] = 0   # Initialize element to 0
        for i in range(0, dimension):           # Iterate through the shared matrix dimension
            # Multiply corresponding elements and sum their values
            result[resultRowI][resultColumnI] += matrix[resultRowI][i] * matrix2[i][resultColumnI]

# Perform the same operation using NumPy for comparison
import numpy as np
results_np = np.dot(matrix, matrix2)






import timeit
import pandas as pd

# List for storing results
results_list = []

# Run the benchmark for 50 iterations
for i in range(50):
    # Measure execution time of the first solution (triple nested loops)
    time_first_solution = timeit.timeit(
        stmt='''
# Performing matrix multiplication
for result_row_i in range(0, dimension):        # Iterate over rows of the result matrix
    for result_col_i in range(0, dimension):     # Iterate over columns of the result matrix
        result[result_row_i][result_col_i] = 0   # Initialize cell to 0
        for k in range(0, dimension):            # Iterate over the shared dimension
            # Multiply corresponding elements and accumulate their sum
            result[result_row_i][result_col_i] += matrix[result_row_i][k] * matrix2[k][result_col_i]
        ''',
        setup='''
matrix = list()
matrix2 = list()
result = list()

# Dimension of the square matrices
dimension = 100

# Create matrices with initial values
for row_i in range(0, dimension):
    row = list()   # Row for the first matrix
    row2 = list()  # Row for the second matrix
    row3 = list()  # Row for the result matrix (initialized with zeros)
    for col_i in range(0, dimension):
        row.append(row_i * dimension + col_i)   # Assign sequential values to the first matrix
        row2.append(row_i * dimension + col_i)  # Assign sequential values to the second matrix
        row3.append(0)                           # Initialize the result matrix with zeros
    # Append generated rows to the matrices
    matrix.append(row)
    matrix2.append(row2)
    result.append(row3)
        ''',
        number=1  # how many times to repeat the statement (1)
    )

    # Measure execution time of the second solution (using NumPy)
    time_second_solution = timeit.timeit(
        stmt='''
results_np = np.dot(matrix, matrix2)
        ''',
        setup='''
import numpy as np
# Dimension of the square matrices
dimension = 100

# Create the first and second matrices with squential values
matrix = np.arange(dimension**2).reshape(dimension, dimension)
matrix2 = np.arange(dimension**2).reshape(dimension, dimension)

# Initialize the result matrix with zeros
result = np.zeros((dimension, dimension), dtype=int)
        ''',
        number=1
    )

    # Add results as dicts
    results_list.append({
        'solution': 'loop',
        'iteration': i,  # store the exact time for each single run
        'time': time_first_solution
    })
    results_list.append({
        'solution': 'numpy',
        'iteration': i,  # store the exact time for each single run
        'time': time_second_solution
    })

# Convert the results list into a DataFrame
frame = pd.DataFrame(results_list)

# Display results
frame






import matplotlib.pyplot as plt
import seaborn as sns

# Create the first plot (boxplot)
sns.boxplot(x="solution", y="time", data=frame)
plt.title("Comparison of execution time distribution for two methods")

# Adjust layout to prevent overlap
plt.tight_layout()

# Show the plot
plt.show()



frame.groupby("solution")["time"].describe()





if 0.1 +0.2 ==0.3:
    print("ok")
else:
    print("not ok")


1.0 / 1_000_000_000_000.0


# Initialize a list with one large floating-point number
floats_are_weird = [1_000_000.0]

# Add one million small floating-point numbers to the list
for i in range(0, 1_000_000):
    floats_are_weird.append(1.0 / 1_000_000_000_000.0)

# Display the first five elements of the list
print(floats_are_weird[:5])

# Sum all numbers in the list
sum1 = 0.0
for num in floats_are_weird:
    sum1 += num
print(sum1)

print("----second------")

# Sort the list in ascending order
floats_are_weird.sort()

# Display the first five (smallest) elements of the sorted list
print(floats_are_weird[:5])

# Display the last five (largest) elements of the sorted list
print(floats_are_weird[-5:])

# Sum all numbers in the sorted list again
sum2 = 0.0
for num in floats_are_weird:
    sum2 += num
print(sum2)






import numpy as np

# Initialize an array with a large number
floats_are_weird = np.array([1_000_000.0])

# Add one million small numbers
small_numbers = np.full(1_000_000, 1.0 / 1_000_000_000_000.0)
floats_are_weird = np.concatenate((floats_are_weird, small_numbers))

# Sum the elements of the array
sum1 = np.sum(floats_are_weird)
print(sum1)

# Sort the array
floats_are_weird.sort()

# Sum again after sorting
sum2 = np.sum(floats_are_weird)
print(sum2)






import timeit
import pandas as pd
import random

# Number of elements to test
num_elements = 100000

# Generate keys and values
keys = [f'key_{i}' for i in range(num_elements)]
values = [random.randint(1, 1000) for _ in range(num_elements)]

# Test setup for the dictionary
dictionary = {'key': keys, 'value': values}

# Test setup for the Pandas DataFrame
df = pd.DataFrame({'key': keys, 'value': values})
df



dictionary



