{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Social Survey (Round 11) - Trust Variables Dimensional Reduction\n",
    "\n",
    "Ondřej Marvan, 477001 \n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This analysis explores the latent structure of trust-related variables in the European Social Survey (ESS) Round 11 data using **Principal Component Analysis (PCA)** and **Factor Analysis**. The goal is to discover how different types of trust—institutional, political, and social—relate to each other and how they vary across European countries.\n",
    "\n",
    "### Variables Analyzed (0-10 scale):\n",
    "| Variable | Description |\n",
    "|----------|-------------|\n",
    "| `trstplt` | Trust in politicians |\n",
    "| `trstplc` | Trust in the police |\n",
    "| `trstprl` | Trust in country's parliament |\n",
    "| `trstprt` | Trust in political parties |\n",
    "| `trstlgl` | Trust in the legal system |\n",
    "| `trstep` | Trust in the European Parliament |\n",
    "| `trstun` | Trust in the United Nations |\n",
    "| `ppltrst` | Social trust (people can be trusted) |\n",
    "| `pplhlp` | People are helpful |\n",
    "| `pplfair` | People are fair |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path - main.csv \n",
    "data_path = \"/home/ondrej-marvan/Documents/GitHub/OBS_DataScience/OBS_DataScience/Autumn 2025/2400-DS1UL Unsupervised Learning/Projects/Task_DimReduction/Data/main.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of respondents: {df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trust variables and labels\n",
    "trust_vars = ['trstplt', 'trstplc', 'trstprl', 'trstprt', 'trstlgl', \n",
    "              'trstep', 'trstun', 'ppltrst', 'pplhlp', 'pplfair']\n",
    "\n",
    "var_labels = {\n",
    "    'trstplt': 'Trust Politicians',\n",
    "    'trstplc': 'Trust Police',\n",
    "    'trstprl': 'Trust Parliament',\n",
    "    'trstprt': 'Trust Parties',\n",
    "    'trstlgl': 'Trust Legal System',\n",
    "    'trstep': 'Trust EU Parliament',\n",
    "    'trstun': 'Trust UN',\n",
    "    'ppltrst': 'Social Trust',\n",
    "    'pplhlp': 'People Helpful',\n",
    "    'pplfair': 'People Fair'\n",
    "}\n",
    "\n",
    "country_names = {\n",
    "    'AT': 'Austria', 'BE': 'Belgium', 'BG': 'Bulgaria', 'CH': 'Switzerland',\n",
    "    'CY': 'Cyprus', 'CZ': 'Czechia', 'DE': 'Germany', 'DK': 'Denmark',\n",
    "    'EE': 'Estonia', 'ES': 'Spain', 'FI': 'Finland', 'FR': 'France',\n",
    "    'GB': 'United Kingdom', 'GR': 'Greece', 'HR': 'Croatia', 'HU': 'Hungary',\n",
    "    'IE': 'Ireland', 'IS': 'Iceland', 'IT': 'Italy', 'LT': 'Lithuania',\n",
    "    'LV': 'Latvia', 'ME': 'Montenegro', 'NL': 'Netherlands', 'NO': 'Norway',\n",
    "    'PL': 'Poland', 'PT': 'Portugal', 'RS': 'Serbia', 'SE': 'Sweden',\n",
    "    'SI': 'Slovenia', 'SK': 'Slovakia', 'UA': 'Ukraine', 'XK': 'Kosovo'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geographical Coverage\n",
    "\n",
    "Keeping the **broadest possible geographical coverage** - all countries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all countries\n",
    "countries = df['cntry'].unique()\n",
    "print(f\"Countries in dataset: {len(countries)}\")\n",
    "print(f\"\\nCountry codes: {sorted(countries)}\")\n",
    "\n",
    "# Sample sizes per country\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Sample Sizes by Country:\")\n",
    "print(\"=\"*50)\n",
    "country_counts = df['cntry'].value_counts().sort_index()\n",
    "for code, count in country_counts.items():\n",
    "    name = country_names.get(code, code)\n",
    "    print(f\"{code} ({name}): {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variable Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working subset\n",
    "df_trust = df[['cntry'] + trust_vars].copy()\n",
    "\n",
    "# Handle missing values (ESS uses codes like 66, 77, 88, 99 for missing)\n",
    "# Valid values are 0-10\n",
    "print(\"Checking for missing/invalid values:\")\n",
    "print(\"-\" * 50)\n",
    "for var in trust_vars:\n",
    "    df_trust[var] = pd.to_numeric(df_trust[var], errors='coerce')\n",
    "    # Replace values outside 0-10 range with NaN\n",
    "    invalid_mask = (df_trust[var] < 0) | (df_trust[var] > 10)\n",
    "    df_trust.loc[invalid_mask, var] = np.nan\n",
    "    n_missing = df_trust[var].isna().sum()\n",
    "    pct_missing = (n_missing / len(df_trust)) * 100\n",
    "    print(f\"{var_labels[var]:20s}: {n_missing:,} missing ({pct_missing:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(\"=\"*70)\n",
    "stats = df_trust[trust_vars].describe().round(2)\n",
    "stats.columns = [var_labels[v] for v in trust_vars]\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of trust variables\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(trust_vars):\n",
    "    df_trust[var].dropna().hist(bins=11, ax=axes[i], edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(var_labels[var], fontsize=10)\n",
    "    axes[i].set_xlabel('Trust Score (0-10)')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('Distribution of Trust Variables', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete case analysis\n",
    "df_complete = df_trust.dropna(subset=trust_vars)\n",
    "print(f\"Complete cases: {len(df_complete):,} out of {len(df_trust):,} ({100*len(df_complete)/len(df_trust):.1f}%)\")\n",
    "print(f\"Countries with complete data: {df_complete['cntry'].nunique()}\")\n",
    "\n",
    "# Extract and standardize features\n",
    "X = df_complete[trust_vars].values\n",
    "countries_complete = df_complete['cntry'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"\\nFeature matrix shape: {X_scaled.shape}\")\n",
    "print(\"Data standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Explained variance\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "# Kaiser criterion\n",
    "n_kaiser = sum(eigenvalues > 1)\n",
    "\n",
    "print(\"Explained Variance by Component:\")\n",
    "print(\"=\"*60)\n",
    "for i, (var, cum, eig) in enumerate(zip(explained_var, cumulative_var, eigenvalues), 1):\n",
    "    kaiser = \"*\" if eig > 1 else \" \"\n",
    "    bar = '█' * int(var * 40)\n",
    "    print(f\"PC{i}: {var*100:5.1f}%  (cum: {cum*100:5.1f}%)  λ={eig:.2f} {kaiser} {bar}\")\n",
    "\n",
    "print(f\"\\n* Kaiser criterion (eigenvalue > 1): Retain {n_kaiser} components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Eigenvalues\n",
    "ax1 = axes[0]\n",
    "ax1.plot(range(1, len(eigenvalues)+1), eigenvalues, 'bo-', linewidth=2, markersize=10)\n",
    "ax1.axhline(y=1, color='r', linestyle='--', linewidth=2, label='Kaiser criterion (λ=1)')\n",
    "ax1.set_xlabel('Principal Component', fontsize=12)\n",
    "ax1.set_ylabel('Eigenvalue', fontsize=12)\n",
    "ax1.set_title('Scree Plot', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(1, len(eigenvalues)+1))\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(1, len(explained_var)+1), explained_var*100, alpha=0.7, color='steelblue', label='Individual')\n",
    "ax2.plot(range(1, len(cumulative_var)+1), cumulative_var*100, 'ro-', linewidth=2, markersize=8, label='Cumulative')\n",
    "ax2.axhline(y=70, color='g', linestyle='--', alpha=0.7, label='70% threshold')\n",
    "ax2.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='80% threshold')\n",
    "ax2.set_xlabel('Principal Component', fontsize=12)\n",
    "ax2.set_ylabel('Variance Explained (%)', fontsize=12)\n",
    "ax2.set_title('Variance Explained', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(1, len(explained_var)+1))\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Component Loadings Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component loadings\n",
    "loadings = pca.components_[:n_kaiser].T\n",
    "loadings_df = pd.DataFrame(\n",
    "    loadings,\n",
    "    index=[var_labels[v] for v in trust_vars],\n",
    "    columns=[f'PC{i+1}' for i in range(n_kaiser)]\n",
    ")\n",
    "\n",
    "print(f\"Component Loadings (retaining {n_kaiser} components):\")\n",
    "print(\"=\"*60)\n",
    "display(loadings_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component interpretation\n",
    "print(\"\\nComponent Interpretation:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(n_kaiser):\n",
    "    print(f\"\\nPC{i+1} ({explained_var[i]*100:.1f}% variance):\")\n",
    "    print(\"-\" * 40)\n",
    "    pc_loadings = loadings_df[f'PC{i+1}'].sort_values(key=abs, ascending=False)\n",
    "    for var, load in pc_loadings.items():\n",
    "        direction = \"+\" if load > 0 else \"-\"\n",
    "        strength = \"STRONG\" if abs(load) > 0.5 else \"moderate\" if abs(load) > 0.3 else \"weak\"\n",
    "        print(f\"  {direction} {var}: {load:+.3f} ({strength})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(loadings_df, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            vmin=-1, vmax=1, ax=ax, cbar_kws={'label': 'Loading'},\n",
    "            linewidths=0.5)\n",
    "ax.set_title('PCA Component Loadings', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Trust Variables', fontsize=12)\n",
    "ax.set_xlabel('Principal Components', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Factor Analysis (Comparison with Varimax Rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor Analysis with Varimax rotation\n",
    "fa = FactorAnalysis(n_components=n_kaiser, rotation='varimax', random_state=42)\n",
    "fa.fit(X_scaled)\n",
    "\n",
    "fa_loadings = pd.DataFrame(\n",
    "    fa.components_.T,\n",
    "    index=[var_labels[v] for v in trust_vars],\n",
    "    columns=[f'Factor{i+1}' for i in range(n_kaiser)]\n",
    ")\n",
    "\n",
    "print(f\"Factor Loadings (Varimax Rotation, {n_kaiser} factors):\")\n",
    "print(\"=\"*60)\n",
    "display(fa_loadings.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PCA and FA loadings\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "sns.heatmap(loadings_df, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            vmin=-1, vmax=1, ax=axes[0], cbar_kws={'label': 'Loading'}, linewidths=0.5)\n",
    "axes[0].set_title('PCA Loadings', fontsize=14, fontweight='bold')\n",
    "\n",
    "sns.heatmap(fa_loadings, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            vmin=-1, vmax=1, ax=axes[1], cbar_kws={'label': 'Loading'}, linewidths=0.5)\n",
    "axes[1].set_title('Factor Analysis Loadings (Varimax)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dimension Reduction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to 2D\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Country': countries_complete\n",
    "})\n",
    "\n",
    "# Country means\n",
    "country_means = df_pca.groupby('Country').agg({'PC1': 'mean', 'PC2': 'mean'}).reset_index()\n",
    "country_means['Country_Name'] = country_means['Country'].map(country_names)\n",
    "\n",
    "print(\"Country Positions in PCA Space:\")\n",
    "print(\"=\"*50)\n",
    "display(country_means.sort_values('PC1', ascending=False).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main scatter plot\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "unique_countries = df_pca['Country'].unique()\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(unique_countries)))\n",
    "color_map = dict(zip(unique_countries, colors))\n",
    "\n",
    "# Individual points\n",
    "for country in unique_countries:\n",
    "    mask = df_pca['Country'] == country\n",
    "    ax.scatter(df_pca.loc[mask, 'PC1'], df_pca.loc[mask, 'PC2'],\n",
    "               c=[color_map[country]], alpha=0.1, s=5)\n",
    "\n",
    "# Country means\n",
    "for _, row in country_means.iterrows():\n",
    "    ax.scatter(row['PC1'], row['PC2'], c=[color_map[row['Country']]],\n",
    "               s=250, edgecolors='black', linewidths=2, zorder=5)\n",
    "    ax.annotate(row['Country'], (row['PC1'], row['PC2']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
    "ax.set_title('European Trust Landscape: PCA of Trust Variables\\n(Small dots: individuals, Large circles: country means)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Biplot Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "scale = 4  # Arrow scale factor\n",
    "\n",
    "# Country means\n",
    "for _, row in country_means.iterrows():\n",
    "    ax.scatter(row['PC1'], row['PC2'], c=[color_map[row['Country']]],\n",
    "               s=350, edgecolors='black', linewidths=2, alpha=0.7, zorder=5)\n",
    "    name = row['Country_Name'] if pd.notna(row['Country_Name']) else row['Country']\n",
    "    ax.annotate(name, (row['PC1'], row['PC2']),\n",
    "                xytext=(7, 7), textcoords='offset points',\n",
    "                fontsize=9, fontweight='bold')\n",
    "\n",
    "# Variable loadings as arrows\n",
    "loadings_2d = pca_2d.components_.T\n",
    "for i, var in enumerate(trust_vars):\n",
    "    ax.arrow(0, 0, loadings_2d[i, 0]*scale, loadings_2d[i, 1]*scale,\n",
    "             head_width=0.12, head_length=0.06, fc='darkred', ec='darkred', alpha=0.9, linewidth=2)\n",
    "    ax.text(loadings_2d[i, 0]*scale*1.12, loadings_2d[i, 1]*scale*1.12,\n",
    "            var_labels[var], fontsize=10, color='darkred', ha='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
    "ax.set_title('PCA Biplot: Countries and Trust Variables\\n(Red arrows: variable loadings, Circles: country means)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Country Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean trust scores by country\n",
    "country_trust_means = df_complete.groupby('cntry')[trust_vars].mean()\n",
    "country_trust_means.columns = [var_labels[v] for v in trust_vars]\n",
    "country_trust_means = country_trust_means.sort_values('Trust Politicians', ascending=False)\n",
    "\n",
    "# Add country names\n",
    "country_trust_means.index = [f\"{idx} ({country_names.get(idx, idx)})\" for idx in country_trust_means.index]\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 16))\n",
    "sns.heatmap(country_trust_means, annot=True, fmt='.1f', cmap='RdYlGn',\n",
    "            ax=ax, cbar_kws={'label': 'Mean Trust Score (0-10)'},\n",
    "            linewidths=0.5)\n",
    "ax.set_title('Trust Levels by Country\\n(Sorted by Trust in Politicians)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Trust Variables', fontsize=12)\n",
    "ax.set_ylabel('Country', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Correlation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = df_complete[trust_vars].corr()\n",
    "corr.columns = [var_labels[v] for v in trust_vars]\n",
    "corr.index = [var_labels[v] for v in trust_vars]\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, vmin=-1, vmax=1, ax=ax, square=True,\n",
    "            cbar_kws={'label': 'Correlation'}, linewidths=0.5)\n",
    "ax.set_title('Correlation Matrix of Trust Variables', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "DATA OVERVIEW:\n",
    "- Total respondents analyzed: {len(df_complete):,}\n",
    "- Countries included: {df_complete['cntry'].nunique()}\n",
    "- Variables: {len(trust_vars)} trust-related measures\n",
    "\n",
    "PCA RESULTS:\n",
    "- PC1 explains {explained_var[0]*100:.1f}% of variance\n",
    "- PC2 explains {explained_var[1]*100:.1f}% of variance\n",
    "- First {n_kaiser} components (Kaiser criterion) explain {cumulative_var[n_kaiser-1]*100:.1f}% of total variance\n",
    "\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. DIMENSION STRUCTURE:\n",
    "   - PC1 captures GENERAL TRUST (all variables load positively)\n",
    "     → People who trust one institution tend to trust others\n",
    "   \n",
    "   - PC2 distinguishes INSTITUTIONAL vs SOCIAL trust\n",
    "     → Political/institutional trust vs interpersonal trust\n",
    "\n",
    "2. COUNTRY PATTERNS:\n",
    "   - Nordic countries tend to show higher trust levels\n",
    "   - Some Eastern European countries show lower institutional trust\n",
    "   - Social trust patterns differ from political trust patterns\n",
    "\n",
    "3. VARIABLE CLUSTERING:\n",
    "   - Political trust cluster: politicians, parties, parliament\n",
    "   - Social trust cluster: ppltrst, pplfair, pplhlp\n",
    "   - Police/legal system: bridge both clusters\n",
    "\n",
    "METHODOLOGY:\n",
    "- Complete case analysis (listwise deletion)\n",
    "- Standardized data (z-scores)\n",
    "- Kaiser criterion for component retention\n",
    "- Varimax rotation for Factor Analysis comparison\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusion**: This dimensional reduction analysis reveals that trust in European societies can be understood through two main dimensions: (1) a general trust factor capturing overall trust propensity, and (2) a dimension distinguishing institutional/political trust from interpersonal/social trust. These findings are consistent with social capital theory and highlight meaningful cross-national variation in trust structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
